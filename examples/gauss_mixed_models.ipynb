{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian mixture models for phase fitting\n",
    "\n",
    "Reads exported data from flow cytometry analysis folder (in which cells were stained with DNA-binding dye such as Propidium Iodide). Fits a combination of three gaussians (representing G0/1, S, G2/M phases) to the fluorescence histogram, then uses the generated model to classify cells in each phase.\n",
    "\n",
    "Individual models could alternatively be used to predict cell phase from multiple samples (i.e. in the case of a control vs treated style experimental design)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tkr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from matplotlib import rc\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn import mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from GEN_Utils import FileHandling\n",
    "logger.info('Import OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, cell_col, upper_thresh=15000, lower_thresh=2500):\n",
    "    # Upper and lower thresholds remove apoptotic and multiploidal cells\n",
    "    #cell_col =fluorescence channel name in which cell phases will be fitted\n",
    "    if lower_thresh:\n",
    "        df = df[df[cell_col] > lower_thresh]\n",
    "        logger.info(f'Lower threshold of {lower_thresh} applied.')\n",
    "    if upper_thresh:\n",
    "        df = df[df[cell_col] < upper_thresh]\n",
    "        logger.info(f'Upper threshold of {upper_thresh} applied.')\n",
    "    # Normalise data to maximum value (theoretically is likely to be equivalent to the upper_thresh)\n",
    "    df[cell_col] = df[cell_col]/upper_thresh\n",
    "    return df\n",
    "\n",
    "def file_processor(input_path, cell_col, upper_thresh=2600, lower_thresh=500):\n",
    "    sample_dict = {}\n",
    "    raw_data = pd.read_csv(input_path)\n",
    "    # sns.distplot(raw_data, bins=1000, hist=True, kde=True, rug=False, fit=None, hist_kws=None, kde_kws=None, rug_kws=None, fit_kws=None, color=None, vertical=False, norm_hist=False, axlabel=None, label=None, ax=None)\n",
    "    # plt.show()\n",
    "    logger.debug('Raw data successfully loaded')\n",
    "    sample_dict['raw_data'] = raw_data.copy()\n",
    "    sample_dict['normalised'] = preprocess(\n",
    "        raw_data, upper_thresh=upper_thresh, lower_thresh=lower_thresh, cell_col=cell_col)\n",
    "    logger.debug(f'{sample_name} normalised.')\n",
    "    return sample_dict\n",
    "\n",
    "def model_fitter(x_array, num_components=3):\n",
    "    # Fit initial data, including preprocessing to generate array\n",
    "    ravelled = np.ravel(x_array).astype(np.float)\n",
    "    shaped = ravelled.reshape(-1, 1)\n",
    "    # establish model\n",
    "    gauss_model = mixture.GaussianMixture(\n",
    "        n_components=num_components, covariance_type='full')\n",
    "    gauss_model.fit(shaped)\n",
    "    return gauss_model\n",
    "\n",
    "def model_plotter(model, x_vals, sample_name=None):\n",
    "    #collect weights etc\n",
    "    weights = gauss_model.weights_\n",
    "    means = gauss_model.means_\n",
    "    covars = gauss_model.covariances_\n",
    "    # Plot individual fits\n",
    "    palette = iter(sns.color_palette(n_colors=len(covars)))\n",
    "    x_vals.sort()\n",
    "    fig = plt.subplots()\n",
    "    sns.distplot(x_vals, bins=100, color='crimson')  # original data\n",
    "    # plot normal distribution for x_values\n",
    "    for x in range(0, len(weights)):\n",
    "        plt.plot(x_vals, weights[x]*stats.norm.pdf(x_vals,\n",
    "                                                   means[x], np.sqrt(covars[x])).ravel(), color=next(palette), label=f'Cluster {x}')\n",
    "    plt.legend()\n",
    "    plt.title(sample_name)\n",
    "    plt.xlabel('Normalised PI Fluorescence (A.U.)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory so that relative path loads work correctly.\n",
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.expanduser('~'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = f'{os.getcwd()}/test_data/flow_cytometry/'\n",
    "\n",
    "output_folder = f'{os.getcwd()}/examples/python/gauss_models/'\n",
    "# Column name containing PI fluorescence information\n",
    "\n",
    "cell_col = 'PI'\n",
    "output_folder_list = [output_folder] + [f'{output_folder}plots/', f'{output_folder}normalised/']\n",
    "\n",
    "for folder in output_folder_list:\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [filename for filename in os.listdir(input_folder)]\n",
    "\n",
    "for filename in filelist[:3]:\n",
    "    input_path = input_folder + filename\n",
    "    filename, file_extension = os.path.splitext(filename)\n",
    "    sample_name = filename.split('_')[1]\n",
    "    # Check raw data\n",
    "    raw_data = pd.read_csv(input_path)\n",
    "    ProfileReport(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(raw_data.columns.tolist()))\n",
    "\n",
    "for x, col in enumerate(raw_data.columns.tolist()):\n",
    "    sns.distplot(raw_data[col], ax=axes[x])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.autoscale()\n",
    "plt.title(sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "filelist = [filename for filename in os.listdir(input_folder)]\n",
    "\n",
    "for filename in filelist[:3]:\n",
    "    input_path = input_folder + filename\n",
    "    filename, file_extension = os.path.splitext(filename)\n",
    "    sample_name = filename.split('_')[1]\n",
    "    sample_dict = file_processor(input_path, cell_col, upper_thresh=2600, lower_thresh=500)\n",
    "    # Generate array of PI normalised values, fit to GMM and plot\n",
    "    x_array = np.array(sample_dict['normalised'][cell_col])\n",
    "    # As a general rule, no point fitting datasets of > 1000 cells (either controls or real)\n",
    "    if x_array.shape[0] < 1000:\n",
    "        logger.info(f'{sample_name} was not processed.')\n",
    "        continue\n",
    "    gauss_model = model_fitter(x_array)\n",
    "    fig = model_plotter(gauss_model, x_array.ravel(), sample_name=sample_name)\n",
    "    plt.savefig(f\"{output_folder}plots/{sample_name}_model.png\")\n",
    "    # Use fitted GMM to predict the cluster for each cell, add to normalised df\n",
    "    sample_dict['normalised']['cluster'] = gauss_model.predict(\n",
    "        np.array(sample_dict['normalised'][cell_col]).reshape(-1, 1))\n",
    "    # Determine which cluster maps to which phase according to mean values\n",
    "    cluster_allocations = pd.DataFrame()\n",
    "    cluster_allocations['names'] = [0, 1, 2]\n",
    "    cluster_allocations['means'] = gauss_model.means_\n",
    "    cluster_allocations = cluster_allocations.sort_values('means')\n",
    "    cluster_allocations['phase'] = ['G', 'S', 'M']\n",
    "    phase_dict = dict(\n",
    "        zip(cluster_allocations['names'], cluster_allocations['phase']))\n",
    "    # Assign phase names to df\n",
    "    sample_dict['normalised']['phase'] = sample_dict['normalised']['cluster'].map(\n",
    "        phase_dict)\n",
    "    # Calculate proportion in each cluster, assign to dictionary\n",
    "    sample_dict['proportions'] = dict(\n",
    "        sample_dict['normalised']['phase'].value_counts() / len(sample_dict['normalised']))\n",
    "    # Plot histogram showing binned dataset\n",
    "    phase_pos = [0.7, 0.6, 0.5]\n",
    "    fig = plt.subplots()\n",
    "    for groupname, groupdata in sample_dict['normalised'].groupby('phase'):\n",
    "        sns.distplot(groupdata[cell_col], bins=100,\n",
    "                     kde=False, norm_hist=False, label=groupname)\n",
    "    for x, phase in enumerate(['G', 'S', 'M']):\n",
    "        proportion = round(sample_dict['proportions'][phase], 2)\n",
    "        plt.annotate(f'{phase}:{proportion}',\n",
    "                     (0.2, phase_pos[x]), xycoords='figure fraction')\n",
    "    plt.legend()\n",
    "    plt.title(sample_name)\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(f'{output_folder}plots/{sample_name}_predict.png')\n",
    "    data_dict[sample_name] = sample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cluster-labelled df to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in data_dict.keys():\n",
    "    data = data_dict[sample]['normalised']\n",
    "    data.to_csv(f\"{output_folder}normalised/{sample}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect proportions into simple df labelled with sample name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(index=data_dict.keys(), columns=['G', 'S', 'M'])\n",
    "\n",
    "for sample in data_dict.keys():\n",
    "    proportions = data_dict[sample]['proportions']\n",
    "    summary.loc[sample, 'G'] = proportions['G']\n",
    "    summary.loc[sample, 'S'] = proportions['S']\n",
    "    summary.loc[sample, 'M'] = proportions['M']\n",
    "\n",
    "summary.rename_axis('sample', inplace=True)\n",
    "summary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.head(10)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "cell_culture",
   "language": "python",
   "name": "cell_culture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
